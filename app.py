# app.py
import streamlit as st
import fitz  # PyMuPDF
import pytesseract
from pdf2image import convert_from_bytes
from PIL import Image
import io
import pandas as pd
import json

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser

## –ò–ó–ú–ï–ù–ï–ù–ò–ï: –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é get_translation_map
from templates import REPORT_TEMPLATES, get_report_template_as_string, get_translation_map

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
st.set_page_config(layout="wide", page_title="–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –§–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –û—Ç—á–µ—Ç–æ–≤")

# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø LLM ---
try:
    PROVIDER_API_KEY = st.secrets["NOVITA_API_KEY"]
except (FileNotFoundError, KeyError):
    st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ NOVITA_API_KEY. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .streamlit/secrets.toml –∏ –¥–æ–±–∞–≤—å—Ç–µ –∫–ª—é—á.")
    st.stop()

llm = ChatOpenAI(
    model_name="deepseek/deepseek-coder",
    openai_api_key=PROVIDER_API_KEY,
    openai_api_base="https://api.novita.ai/v3/openai",
    temperature=0.1,
    max_tokens=4096
)

# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---
# ... (—Ñ—É–Ω–∫—Ü–∏–∏ extract_text_from_file, classify_report, extract_data_with_template –æ—Å—Ç–∞—é—Ç—Å—è –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô) ...
@st.cache_data
def extract_text_from_file(file_bytes, filename):
    # ... –∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    pass

@st.cache_data
def classify_report(_llm, text: str) -> str:
    # ... –∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    pass

@st.cache_data
def extract_data_with_template(_llm, text: str, report_type: str) -> list:
    # ... –∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    pass

# –û—Å—Ç–∞–≤–∏–º —Ç—É—Ç –∑–∞–≥–ª—É—à–∫–∏, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –æ–Ω–∏ –Ω–µ –º–µ–Ω—è—é—Ç—Å—è
extract_text_from_file = st.session_state.get('extract_text_from_file_func', extract_text_from_file)
classify_report = st.session_state.get('classify_report_func', classify_report)
extract_data_with_template = st.session_state.get('extract_data_with_template_func', extract_data_with_template)
# –ü–æ–ª–Ω—ã–π –∫–æ–¥ —ç—Ç–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π –µ—Å—Ç—å –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º –æ—Ç–≤–µ—Ç–µ.

def to_excel_bytes(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Report')
    return output.getvalue()

## –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ù–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Ä—É—Å—Å–∫–∏–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
def enrich_data_with_russian_names(data: list, report_type: str) -> list:
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Ä—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–∞—Ç–µ–π –≤ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."""
    translation_map = get_translation_map(report_type)
    enriched_data = []
    
    for item in data:
        english_name = item.get("line_item")
        if not english_name:
            continue
            
        russian_name = translation_map.get(english_name, "–°—Ç–∞—Ç—å—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —à–∞–±–ª–æ–Ω–µ")
        
        enriched_data.append({
            "–°—Ç–∞—Ç—å—è (RU)": russian_name,
            "Line Item (EN)": english_name,
            "value": item.get("value"),
            "year": item.get("year"),
            "unit": item.get("unit")
        })
    return enriched_data

# --- –ò–ù–¢–ï–†–§–ï–ô–° –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ---
st.title("ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ä–∞–∑–±–æ—Ä–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –æ—Ç—á–µ—Ç–æ–≤")

st.sidebar.header("–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞")
uploaded_file = st.sidebar.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–∫–∞–Ω –æ—Ç—á–µ—Ç–∞",
    type=["pdf", "png", "jpg", "jpeg"]
)

if uploaded_file:
    file_bytes = uploaded_file.getvalue()
    
    with st.spinner("1/3 –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞..."):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–¥ —Ñ—É–Ω–∫—Ü–∏–π –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞
        # –ó–¥–µ—Å—å –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ –æ–ø—É—â–µ–Ω
        extracted_text = extract_text_from_file(file_bytes, uploaded_file.name)
    
    if not extracted_text:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞.")
    else:
        st.success("‚úÖ –®–∞–≥ 1: –¢–µ–∫—Å—Ç —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω.")
        
        with st.spinner("2/3 –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞ –æ—Ç—á–µ—Ç–∞..."):
            report_type = classify_report(llm, extracted_text)
        
        if report_type not in REPORT_TEMPLATES:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –æ—Ç—á–µ—Ç–∞. LLM –≤–µ—Ä–Ω—É–ª: '{report_type}'")
        else:
            st.success(f"‚úÖ –®–∞–≥ 2: –û—Ç—á–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω –∫–∞–∫ **{report_type}**.")
            
            with st.spinner(f"3/3 –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ —à–∞–±–ª–æ–Ω—É..."):
                structured_data = extract_data_with_template(llm, extracted_text, report_type)
            
            if not structured_data:
                st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")
            else:
                st.success("‚úÖ –®–∞–≥ 3: –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã!")

                ## –ò–ó–ú–ï–ù–ï–ù–ò–ï: –î–æ–±–∞–≤–ª—è–µ–º —à–∞–≥ –æ–±–æ–≥–∞—â–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
                final_data = enrich_data_with_russian_names(structured_data, report_type)
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –Ω–µ –±—ã–ª–æ –Ω–∞–π–¥–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ
                df = pd.DataFrame([item for item in final_data if item.get('value') is not None])
                
                st.header("–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞
                if not df.empty:
                    df = df[["–°—Ç–∞—Ç—å—è (RU)", "Line Item (EN)", "value", "year", "unit"]]
                st.dataframe(df, use_container_width=True)
                
                # –ö–Ω–æ–ø–∫–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                excel_bytes = to_excel_bytes(df)
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å –æ—Ç—á–µ—Ç –≤ Excel",
                    data=excel_bytes,
                    file_name=f"standard_report_{uploaded_file.name.split('.')[0]}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                
                with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω—ã–π JSON –æ—Ç LLM (–¥–æ –æ–±–æ–≥–∞—â–µ–Ω–∏—è)"):
                    st.json(structured_data)
else:
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å.")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –≤ session_state, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ
st.session_state['extract_text_from_file_func'] = extract_text_from_file
st.session_state['classify_report_func'] = classify_report
st.session_state['extract_data_with_template_func'] = extract_data_with_template
