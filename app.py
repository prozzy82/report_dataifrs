import os
import streamlit as st
import fitz  # PyMuPDF
import pytesseract
from pdf2image import convert_from_bytes
from PIL import Image
import io
import pandas as pd
import json

# –ò–º–ø–æ—Ä—Ç –∏–∑ –≤–∞—à–µ–≥–æ —Ñ–∞–π–ª–∞ —à–∞–±–ª–æ–Ω–æ–≤
from templates import REPORT_TEMPLATES, get_report_template_as_string, get_translation_map

# –ò–º–ø–æ—Ä—Ç—ã LangChain
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from langchain_core.exceptions import OutputParserException

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
st.set_page_config(layout="wide", page_title="–£–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è –û—Ç—á–µ—Ç–∞")

# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø LLM ---
try:
    PROVIDER_API_KEY = st.secrets.get("NOVITA_API_KEY") or os.getenv("PROVIDER_API_KEY")
    if not PROVIDER_API_KEY:
        raise KeyError
except (FileNotFoundError, KeyError):
    st.error("–ö–ª—é—á API –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è PROVIDER_API_KEY –∏–ª–∏ —Å–æ–∑–¥–∞–π—Ç–µ .streamlit/secrets.toml.")
    st.stop()

llm = ChatOpenAI(
    model_name="mistralai/mistral-7b-instruct",
    openai_api_key=PROVIDER_API_KEY,
    openai_api_base="https://api.novita.ai/v3/openai",
    temperature=0.1
)

# --- –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø –§–£–ù–ö–¶–ò–ô ---

@st.cache_data
def extract_text_from_file(file_bytes, filename):
    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    try:
        ext = os.path.splitext(filename)[1].lower()
        if ext == ".pdf":
            with fitz.open(stream=io.BytesIO(file_bytes), filetype="pdf") as doc:
                text = "".join(page.get_text() for page in doc)
            if len(text.strip()) < 150:
                st.warning(f"–¢–µ–∫—Å—Ç–æ–≤—ã–π —Å–ª–æ–π –≤ '{filename}' –ø—É—Å—Ç. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è OCR...")
                images = convert_from_bytes(file_bytes, dpi=300)
                text = "\n".join([pytesseract.image_to_string(img, lang='rus+eng', config='--psm 6') for img in images])
        elif ext in [".png", ".jpg", ".jpeg"]:
            image = Image.open(io.BytesIO(file_bytes))
            text = pytesseract.image_to_string(image, lang='rus+eng', config='--psm 6')
        else: return None
        return text.strip()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ '{filename}': {e}")
        return None

@st.cache_data
def classify_report(_llm, text: str) -> str:
    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    parser = StrOutputParser()
    prompt = ChatPromptTemplate.from_template(
        "–û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞. –û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –æ–¥–Ω–∏–º –∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: {report_types}.\n\n–¢–µ–∫—Å—Ç:\n---\n{text_snippet}\n---"
    )
    chain = prompt | _llm | parser
    report_types_str = ", ".join(REPORT_TEMPLATES.keys())
    response = chain.invoke({"text_snippet": text[:4000], "report_types": report_types_str})
    for report_type in REPORT_TEMPLATES.keys():
        if report_type in response:
            return report_type
    return "Unknown"

# --- –ò–ó–ú–ï–ù–ï–ù–ò–ï ‚Ññ1: –û–ë–ù–û–í–õ–ï–ù–ù–´–ô –ü–†–û–ú–ü–¢ –î–õ–Ø –ù–ï–°–ö–û–õ–¨–ö–ò–• –ü–ï–†–ò–û–î–û–í ---
@st.cache_data
def extract_data_with_template(_llm, text: str, report_type: str) -> list | None:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ –≤—Å–µ–º –ø–µ—Ä–∏–æ–¥–∞–º –∏–∑ —Ç–µ–∫—Å—Ç–∞ –æ—Ç—á–µ—Ç–∞."""
    template_items = get_report_template_as_string(report_type)
    if not template_items: return []

    parser = JsonOutputParser()
    prompt = ChatPromptTemplate.from_messages([
        ("system",
         "–¢—ã ‚Äî –≤—ã—Å–æ–∫–æ—Ç–æ—á–Ω—ã–π —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –æ—Ç—á–µ—Ç–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å—Ç—Ä–æ–≥–æ –∑–∞–¥–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ JSON. "
         "–¢–µ–±–µ –ó–ê–ü–†–ï–©–ï–ù–û –¥–æ–±–∞–≤–ª—è—Ç—å –ª—é–±—ã–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è –∏–ª–∏ —Ç–µ–∫—Å—Ç, –∫—Ä–æ–º–µ —á–∏—Å—Ç–æ–≥–æ JSON."
         "\n\n–ü–†–ê–í–ò–õ–ê:"
         "\n1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –æ—Ç—á–µ—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∑–∞ –ù–ï–°–ö–û–õ–¨–ö–û –ü–ï–†–ò–û–î–û–í (–≥–æ–¥–æ–≤)."
         "\n2. –î–ª—è –∫–∞–∂–¥–æ–π –°–¢–ê–ù–î–ê–†–¢–ù–û–ô —Å—Ç–∞—Ç—å–∏ –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏ IFRS –æ–ø—Ä–µ–¥–µ–ª–∏ –°–û–û–¢–í–ï–¢–°–¢–í–£–Æ–©–£–Æ —Å—Ç–∞—Ç—å—é –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ç–µ–∫—Å—Ç–µ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞, –≤ —Å–ª—É—á–∞–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–∏–∑–≤–µ–¥–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—é –∑–Ω–∞—á–µ–Ω–∏–π —Å—Ç–∞—Ç–µ–π."
         "\n3. –î–ª—è –ö–ê–ñ–î–û–ì–û –ø–µ—Ä–∏–æ–¥–∞, –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –≤ —Ç–µ–∫—Å—Ç–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≥–æ–¥–∞-–∫–æ–ª–æ–Ω–∫–∏), –∏–∑–≤–ª–µ–∫–∏ —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ."
         "\n4. –°–æ–∑–¥–∞–π –æ–±—ä–µ–∫—Ç –¥–ª—è –∫–∞–∂–¥–æ–π –°–¢–ê–ù–î–ê–†–¢–ù–û–ô —Å—Ç–∞—Ç—å–∏. –í–Ω—É—Ç—Ä–∏ –Ω–µ–≥–æ, –≤ –º–∞—Å—Å–∏–≤–µ `values_by_period`, —Å–æ–∑–¥–∞–π –æ—Ç–¥–µ–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç –¥–ª—è –ö–ê–ñ–î–û–ì–û –ø–µ—Ä–∏–æ–¥–∞."
         "\n5. –í –ø–æ–ª–µ 'components' –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞ —É–∫–∞–∂–∏, –∏–∑ –∫–∞–∫–∏—Ö –∏—Å—Ö–æ–¥–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –±—ã–ª–æ –ø–æ–ª—É—á–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ."
         "\n6. –ï—Å–ª–∏ –¥–ª—è —Å—Ç–∞—Ç—å–∏ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π —Å—Ç–∞—Ç—å–∏ –∏–∑ —à–∞–±–ª–æ–Ω–∞ –Ω–∏ –∑–∞ –æ–¥–∏–Ω –ø–µ—Ä–∏–æ–¥, —É–∫–∞–∂–∏ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π —Å—Ç–∞—Ç—å–∏ –∏ –µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –≤–∏–¥–µ."
         "\n7. –ß–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ `float` –∏–ª–∏ `int`. –î–µ—Å—è—Ç–∏—á–Ω—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å - —Ç–æ—á–∫–∞."
         "\n8. –¢–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¢–û–õ–¨–ö–û JSON-–º–∞—Å—Å–∏–≤–æ–º –æ–±—ä–µ–∫—Ç–æ–≤."
         "\n\n–°–ü–ò–°–û–ö –°–¢–ê–ù–î–ê–†–¢–ù–´–• –°–¢–ê–¢–ï–ô:\n{template_items}"
         "\n\n–§–û–†–ú–ê–¢ –í–´–í–û–î–ê:\n```json\n"
         "[\n"
         "  {{\n"
         "    \"line_item\": \"–ê–Ω–≥–ª–∏–π—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π —Å—Ç–∞—Ç—å–∏\",\n"
         "    \"unit\": \"–µ–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è\",\n"
         "    \"values_by_period\": [\n"
         "      {{\n"
         "        \"period\": \"2024\",\n"
         "        \"value\": <—á–∏—Å–ª–æ –∏–ª–∏ null>,\n"
         "        \"components\": [ {{ \"source_item\": \"–ò—Å—Ö–æ–¥–Ω–∞—è —Å—Ç–∞—Ç—å—è 1\", \"source_value\": <—á–∏—Å–ª–æ> }} ]\n"
         "      }},\n"
         "      {{\n"
         "        \"period\": \"2023\",\n"
         "        \"value\": <—á–∏—Å–ª–æ –∏–ª–∏ null>,\n"
         "        \"components\": [ {{ \"source_item\": \"–ò—Å—Ö–æ–¥–Ω–∞—è —Å—Ç–∞—Ç—å—è 1\", \"source_value\": <—á–∏—Å–ª–æ> }} ]\n"
         "      }}\n"
         "    ]\n"
         "  }}\n"
         "]\n"
         "```"
         ),
        ("user", "–í–æ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ò–∑–≤–ª–µ–∫–∏ –¥–∞–Ω–Ω—ã–µ –ø–æ –í–°–ï–ú –ü–ï–†–ò–û–î–ê–ú —Å—Ç—Ä–æ–≥–æ –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º –∏ –≤–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON.\n\n–¢–ï–ö–°–¢:\n---\n{text}\n---")
    ])

    chain = prompt | _llm | parser
    try:
        return chain.invoke({"text": text, "template_items": template_items})
    except Exception as e:
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –∏–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –æ—Ç–≤–µ—Ç–∞ LLM: {e}")
        # –ü–æ–ø—Ä–æ–±—É–µ–º "–ø–æ—á–∏–Ω–∏—Ç—å" JSON, –µ—Å–ª–∏ –æ–Ω –æ–±–µ—Ä–Ω—É—Ç –≤ —Ç–µ–∫—Å—Ç
        if hasattr(e, 'llm_output'):
            raw_output = e.llm_output
            st.warning("–ü—ã—Ç–∞—é—Å—å –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞...")
            try:
                json_part = raw_output[raw_output.find('['):raw_output.rfind(']')+1]
                return json.loads(json_part)
            except Exception:
                st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏—Å–ø—Ä–∞–≤–∏—Ç—å JSON.")
                st.code(raw_output)
        return None

# --- –ò–ó–ú–ï–ù–ï–ù–ò–ï ‚Ññ2: –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø –î–õ–Ø "–†–ê–ó–í–û–†–ê–ß–ò–í–ê–ù–ò–Ø" –î–ê–ù–ù–´–• ---
def flatten_data_for_display(data: list, report_type: str) -> list:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤–ª–æ–∂–µ–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö –≤ –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ –¥–ª—è DataFrame."""
    flat_list = []
    translation_map = get_translation_map(report_type)
    
    for item in data:
        english_name = item.get("line_item")
        russian_name = translation_map.get(english_name, "N/A")
        unit = item.get("unit")
        
        if not item.get("values_by_period"):
            continue

        for period_data in item["values_by_period"]:
            if period_data.get("value") is not None:
                flat_list.append({
                    "–°—Ç–∞—Ç—å—è (RU)": russian_name,
                    "Line Item (EN)": english_name,
                    "unit": unit,
                    "period": period_data.get("period"),
                    "value": period_data.get("value"),
                    "components": period_data.get("components", [])
                })
    return flat_list

def to_excel_bytes(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Report')
    return output.getvalue()

# --- –ò–ù–¢–ï–†–§–ï–ô–° –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ---
st.title("–£–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è –û—Ç—á–µ—Ç–∞")

st.sidebar.header("–ó–∞–≥—Ä—É–∑–∫–∞ –§–∞–π–ª–æ–≤")
uploaded_files = st.sidebar.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–∫–∞–Ω—ã –æ—Ç—á–µ—Ç–∞", type=["pdf", "png", "jpg", "jpeg"], accept_multiple_files=True
)

if uploaded_files:
    if "processed_data" not in st.session_state or st.session_state.get("file_names") != [f.name for f in uploaded_files]:
        st.session_state.file_names = [f.name for f in uploaded_files]
        all_text = ""
        with st.spinner("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–æ–≤..."):
            for uploaded_file in uploaded_files:
                all_text += f"\n\n--- –ù–ê–ß–ê–õ–û –§–ê–ô–õ–ê: {uploaded_file.name} ---\n\n{extract_text_from_file(uploaded_file.getvalue(), uploaded_file.name)}"
        st.session_state.all_text = all_text.strip()
        st.session_state.processed_data = None

    all_text = st.session_state.get("all_text", "")
    if not all_text:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç.")
        st.stop()

    st.info(f"–û–±—â–∏–π –æ–±—ä–µ–º —Ç–µ–∫—Å—Ç–∞: {len(all_text)} —Å–∏–º–≤–æ–ª–æ–≤.")
    
    with st.spinner("–®–∞–≥ 1/2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞ –æ—Ç—á–µ—Ç–∞..."):
        report_type = classify_report(llm, all_text)

    if report_type == "Unknown":
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –æ—Ç—á–µ—Ç–∞.")
    else:
        st.success(f"‚úÖ –û—Ç—á–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω –∫–∞–∫ **{report_type}**.")
        with st.spinner("–®–∞–≥ 2/2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—Å–µ–º –ø–µ—Ä–∏–æ–¥–∞–º..."):
            structured_data = extract_data_with_template(llm, all_text, report_type)
        if structured_data is None:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ.")
        else:
            st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã!")
            st.session_state.processed_data = structured_data

    # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï ‚Ññ3: –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê –û–¢–û–ë–†–ê–ñ–ï–ù–ò–Ø ---
    if st.session_state.get("processed_data"):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∫ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—é
        flat_data = flatten_data_for_display(st.session_state.processed_data, report_type)
        df = pd.DataFrame(flat_data)
        
        st.header("–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        if not df.empty:
            def format_components(components_list):
                if not isinstance(components_list, list) or not components_list: return "–ü—Ä—è–º–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ"
                def format_val(v):
                    try: return f"{float(v):,.0f}".replace(",", " ")
                    except (ValueError, TypeError): return str(v)
                return "; ".join([f"{c.get('source_item', 'N/A')} ({format_val(c.get('source_value'))})" for c in components_list])

            df['–ò—Å—Ç–æ—á–Ω–∏–∫ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏'] = df['components'].apply(format_components)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏: —Å–Ω–∞—á–∞–ª–∞ –ø–æ —Å—Ç–∞—Ç—å–µ, –ø–æ—Ç–æ–º –ø–æ –ø–µ—Ä–∏–æ–¥—É (–≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ)
            df.sort_values(by=['–°—Ç–∞—Ç—å—è (RU)', 'period'], ascending=[True, False], inplace=True)
            
            # –§–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫
            df = df[["–°—Ç–∞—Ç—å—è (RU)", "value", "period", "–ò—Å—Ç–æ—á–Ω–∏–∫ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏", "unit"]]
            df.rename(columns={
                '–°—Ç–∞—Ç—å—è (RU)': '–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è',
                'value': '–ò—Ç–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ',
                'period': '–ü–µ—Ä–∏–æ–¥',
                'unit': '–ï–¥. –∏–∑–º.'
            }, inplace=True)

            st.dataframe(df, use_container_width=True, hide_index=True)
            
            excel_bytes = to_excel_bytes(df)
            st.download_button("üì• –°–∫–∞—á–∞—Ç—å –æ—Ç—á–µ—Ç –≤ Excel", excel_bytes, f"standard_report_{report_type.replace(' ', '_')}.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        else:
            st.warning("–í —Ç–µ–∫—Å—Ç–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π —Å—Ç–∞—Ç—å–∏ –∏–∑ —à–∞–±–ª–æ–Ω–∞ —Å —á–∏—Å–ª–æ–≤—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º.")
        
        with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω—ã–π JSON –æ—Ç LLM (–≤–ª–æ–∂–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)"):
            st.json(st.session_state.processed_data)
        with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å –≤–µ—Å—å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç"):
            st.text_area("–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç", all_text, height=400)
else:
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑.")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –≤ session_state
st.session_state['extract_text_from_file_func'] = extract_text_from_file
st.session_state['classify_report_func'] = classify_report
st.session_state['extract_data_with_template_func'] = extract_data_with_template
