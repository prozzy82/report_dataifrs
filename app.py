import os
import streamlit as st
import fitz  # PyMuPDF
import pytesseract
from pdf2image import convert_from_bytes
from PIL import Image
import io
import pandas as pd
import json

# –ò–º–ø–æ—Ä—Ç –∏–∑ –≤–∞—à–µ–≥–æ —Ñ–∞–π–ª–∞ —à–∞–±–ª–æ–Ω–æ–≤
from templates import REPORT_TEMPLATES, get_report_template_as_string, get_translation_map

# –ò–º–ø–æ—Ä—Ç—ã LangChain
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from langchain_core.exceptions import OutputParserException

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
st.set_page_config(layout="wide", page_title="–£–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞")

# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø LLM ---
# –ò—Å–ø–æ–ª—å–∑—É–µ–º st.secrets –¥–ª—è –∫–ª—é—á–∞, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –ª—É—á—à–µ–π –ø—Ä–∞–∫—Ç–∏–∫–æ–π –¥–ª—è Streamlit
try:
    PROVIDER_API_KEY = os.getenv("PROVIDER_API_KEY")
except (FileNotFoundError, KeyError):
    st.error("–ö–ª—é—á 'NOVITA_API_KEY' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .streamlit/secrets.toml –∏ –¥–æ–±–∞–≤—å—Ç–µ –µ–≥–æ.")
    st.stop()

llm = ChatOpenAI(
    model_name="google/gemma-3-27b-it",
    openai_api_key=PROVIDER_API_KEY,
    openai_api_base="https://api.novita.ai/v3/openai",
    temperature=0.1
)

# --- –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø –§–£–ù–ö–¶–ò–ô ---

@st.cache_data
def extract_text_from_file(file_bytes, filename):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF –∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞—è —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Å–ª–æ–π, –∞ –∑–∞—Ç–µ–º OCR."""
    try:
        ext = os.path.splitext(filename)[1].lower()
        text = ""

        if ext == ".pdf":
            # –ü–æ–ø—ã—Ç–∫–∞ ‚Ññ1: –ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Å–ª–æ–π (–±—ã—Å—Ç—Ä–æ –∏ —Ç–æ—á–Ω–æ)
            with fitz.open(stream=io.BytesIO(file_bytes), filetype="pdf") as doc:
                text = "".join(page.get_text() for page in doc)

            # –ü–æ–ø—ã—Ç–∫–∞ ‚Ññ2: –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –º–∞–ª–æ (–≤–µ—Ä–æ—è—Ç–Ω–æ, —Å–∫–∞–Ω), –∏—Å–ø–æ–ª—å–∑—É–µ–º OCR
            if len(text.strip()) < 150:
                st.warning(f"–í '{filename}' —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Å–ª–æ–π –ø—É—Å—Ç –∏–ª–∏ –º–∞–ª. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è OCR (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)...")
                images = convert_from_bytes(file_bytes, dpi=300)
                ocr_texts = []
                for i, image in enumerate(images):
                    st.sidebar.text(f"  - –û–±—Ä–∞–±–æ—Ç–∫–∞ OCR —Å—Ç—Ä. {i+1}/{len(images)}...")
                    ocr_texts.append(pytesseract.image_to_string(image, lang='rus+eng', config='--psm 6'))
                text = "\n".join(ocr_texts)

        elif ext in [".png", ".jpg", ".jpeg"]:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ OCR
            image = Image.open(io.BytesIO(file_bytes))
            text = pytesseract.image_to_string(image, lang='rus+eng', config='--psm 6')

        else:
            st.error(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {ext}")
            return None

        return text.strip()

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ '{filename}': {e}")
        return None

@st.cache_data
def classify_report(_llm, text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –æ—Ç—á–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é LLM."""
    parser = StrOutputParser()
    prompt = ChatPromptTemplate.from_template(
        "–û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞. –û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –æ–¥–Ω–∏–º –∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: {report_types}. –ù–∏–∫–∞–∫–∏—Ö –¥—Ä—É–≥–∏—Ö —Å–ª–æ–≤.\n\n"
        "–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–ø–µ—Ä–≤—ã–µ 4000 —Å–∏–º–≤–æ–ª–æ–≤):\n---\n{text_snippet}\n---"
    )
    chain = prompt | _llm | parser
    report_types_str = ", ".join(REPORT_TEMPLATES.keys())
    response = chain.invoke({"text_snippet": text[:4000], "report_types": report_types_str})

    # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    for report_type in REPORT_TEMPLATES.keys():
        if report_type in response:
            return report_type
    return "Unknown"

@st.cache_data
def extract_data_with_template(_llm, text: str, report_type: str) -> list | None:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –æ—Ç—á–µ—Ç–∞ –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–º—É —à–∞–±–ª–æ–Ω—É —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º."""
    template_items = get_report_template_as_string(report_type)
    if not template_items:
        return []

    parser = JsonOutputParser()

    prompt = ChatPromptTemplate.from_messages([
        ("system",
         "–¢—ã ‚Äî –≤—ã—Å–æ–∫–æ—Ç–æ—á–Ω—ã–π —Ä–æ–±–æ—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö. –¢–≤–æ—è –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞ ‚Äî –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON. "
         "–¢–µ–±–µ –ó–ê–ü–†–ï–©–ï–ù–û –¥–æ–±–∞–≤–ª—è—Ç—å –ª—é–±—ã–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è –∏–ª–∏ –ª—é–±–æ–π –¥—Ä—É–≥–æ–π —Ç–µ–∫—Å—Ç, –∫—Ä–æ–º–µ —á–∏—Å—Ç–æ–≥–æ JSON."
         "\n\n–ü–†–ê–í–ò–õ–ê:"
         "\n1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞."
         "\n2. –ù–∞–π–¥–∏ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç–∞—Ç—å–∏ –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞."
         "\n3. –ï—Å–ª–∏ —Å—Ç–∞—Ç—å—è –∏–∑ —Å–ø–∏—Å–∫–∞ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ç–µ–∫—Å—Ç–µ, –∏–∑–≤–ª–µ–∫–∏ –µ–µ —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ ('value'), –≥–æ–¥ ('year') –∏ –µ–¥–∏–Ω–∏—Ü—É –∏–∑–º–µ—Ä–µ–Ω–∏—è ('unit'). –ß–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ `float` –∏–ª–∏ `int`, –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤-—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π. –î–µ—Å—è—Ç–∏—á–Ω—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å - —Ç–æ—á–∫–∞."
         "\n4. –ï—Å–ª–∏ —Å—Ç–∞—Ç—å—è –∏–∑ —Å–ø–∏—Å–∫–∞ –ù–ï –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ç–µ–∫—Å—Ç–µ, –∑–Ω–∞—á–µ–Ω–∏–µ 'value' –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å `null`."
         "\n5. –¢–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¢–û–õ–¨–ö–û JSON-–º–∞—Å—Å–∏–≤–æ–º –æ–±—ä–µ–∫—Ç–æ–≤. –ù–∞—á–∏–Ω–∞–π –æ—Ç–≤–µ—Ç —Å `[` –∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞–π `]`."
         "\n6. –ù–µ —É—á–∏—Ç—ã–≤–∞–π –∫–æ–ª–æ–Ω–∫—É —Å –∫–æ–¥–∞–º–∏ —Å—Ç–∞—Ç–µ–π –∏–ª–∏ –ø—Ä–∏–º–µ—á–∞–Ω–∏—è–º–∏ –∫ —Å—Ç–∞—Ç—å—è–º - –ü—Ä–∏–º. –∏–ª–∏ –ö–æ–¥, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–π —Ç–æ–ª—å–∫–æ –∫–æ–ª–æ–Ω–∫–∏ —Å–æ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ —Å—Ç–∞—Ç–µ–π –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º. "
         "\n\n–°–ü–ò–°–û–ö –°–¢–ê–¢–ï–ô –î–õ–Ø –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø:\n{template_items}"
         "\n\n–§–û–†–ú–ê–¢ –í–´–í–û–î–ê:\n```json\n"
         "[\n"
         "  {{\n"
         "    \"line_item\": \"–ê–Ω–≥–ª–∏–π—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –∏–∑ —Å–ø–∏—Å–∫–∞\",\n"
         "    \"value\": <—á–∏—Å–ª–æ –∏–ª–∏ null>,\n"
         "    \"year\": <–≥–æ–¥ –∏–ª–∏ –ø–µ—Ä–∏–æ–¥ –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞>,\n"
         "    \"unit\": \"–µ–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞\"\n"
         "  }}\n"
         "]\n"
         "```"
         ),
        ("user",
         "–í–æ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ò–∑–≤–ª–µ–∫–∏ –¥–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–≥–æ –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º –∏ –≤–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON.\n\n"
         "–¢–ï–ö–°–¢ –û–¢–ß–ï–¢–ê:\n---\n{text}\n---"
         )
    ])

    chain = prompt | _llm | parser
    
    try:
        return chain.invoke({"text": text, "template_items": template_items})
    except OutputParserException as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM.")
        raw_output = e.llm_output
        st.warning("–û—Ç–≤–µ—Ç LLM —Å–æ–¥–µ—Ä–∂–∞–ª –ª–∏—à–Ω–∏–π —Ç–µ–∫—Å—Ç. –ü—ã—Ç–∞—é—Å—å –∏–∑–≤–ª–µ—á—å JSON...")
        try:
            # –ò—â–µ–º –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü JSON-–º–∞—Å—Å–∏–≤–∞ –≤ "–≥—Ä—è–∑–Ω–æ–º" –æ—Ç–≤–µ—Ç–µ
            json_start = raw_output.find('[')
            json_end = raw_output.rfind(']') + 1
            if json_start != -1 and json_end != 0:
                json_part = raw_output[json_start:json_end]
                parsed_json = json.loads(json_part)
                st.success("JSON —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω –∏–∑ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞!")
                return parsed_json
            else:
                raise ValueError("JSON-–º–∞—Å—Å–∏–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
        except (ValueError, json.JSONDecodeError):
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏—Å–ø—Ä–∞–≤–∏—Ç—å JSON. –û—Ç–≤–µ—Ç –æ—Ç LLM –±—ã–ª –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º.")
            st.code(raw_output, language='text') # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º "—Å—ã—Ä–æ–π" –æ—Ç–≤–µ—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            return None
    except Exception as e:
        st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ LLM: {e}")
        return None

def enrich_data_with_russian_names(data: list, report_type: str) -> list:
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Ä—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–∞—Ç–µ–π –≤ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."""
    translation_map = get_translation_map(report_type)
    enriched_data = []
    for item in data:
        english_name = item.get("line_item")
        if not english_name:
            continue
        russian_name = translation_map.get(english_name, "–°—Ç–∞—Ç—å—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —à–∞–±–ª–æ–Ω–µ")
        enriched_data.append({
            "–°—Ç–∞—Ç—å—è (RU)": russian_name,
            "Line Item (EN)": english_name,
            "value": item.get("value"),
            "year": item.get("year"),
            "unit": item.get("unit")
        })
    return enriched_data

def to_excel_bytes(df):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç DataFrame –≤ –±–∞–π—Ç—ã Excel —Ñ–∞–π–ª–∞."""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Report')
    return output.getvalue()

# --- –ò–ù–¢–ï–†–§–ï–ô–° –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ---
st.title("ü§ñ –£–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏")

st.sidebar.header("–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤")
uploaded_files = st.sidebar.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–∫–∞–Ω—ã –æ—Ç—á–µ—Ç–∞ (–æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤)",
    type=["pdf", "png", "jpg", "jpeg"],
    accept_multiple_files=True
)

if uploaded_files:
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º session_state –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if "processed_data" not in st.session_state or st.session_state.get("file_names") != [f.name for f in uploaded_files]:
        st.session_state.file_names = [f.name for f in uploaded_files]
        all_text = ""
        st.sidebar.subheader("–ü—Ä–æ–≥—Ä–µ—Å—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        for uploaded_file in uploaded_files:
            file_bytes = uploaded_file.getvalue()
            st.sidebar.text(f"-> –§–∞–π–ª: {uploaded_file.name}")
            extracted_text = extract_text_from_file(file_bytes, uploaded_file.name)
            if extracted_text:
                all_text += f"\n\n--- –ù–ê–ß–ê–õ–û –§–ê–ô–õ–ê: {uploaded_file.name} ---\n\n{extracted_text}\n\n--- –ö–û–ù–ï–¶ –§–ê–ô–õ–ê: {uploaded_file.name} ---"
        st.session_state.all_text = all_text.strip()
        st.session_state.processed_data = None # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
    
    if not st.session_state.get("all_text"):
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –Ω–∏ –∏–∑ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.")
        st.stop()
    
    all_text = st.session_state.get("all_text")
    st.info(f"–û–±—â–∏–π –æ–±—ä–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {len(all_text)} —Å–∏–º–≤–æ–ª–æ–≤.")
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    with st.spinner("–®–∞–≥ 1/2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞ –æ—Ç—á–µ—Ç–∞..."):
        report_type = classify_report(llm, all_text)

    if report_type not in REPORT_TEMPLATES:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –æ—Ç—á–µ—Ç–∞. LLM –≤–µ—Ä–Ω—É–ª: '{report_type}'")
    else:
        st.success(f"‚úÖ –û—Ç—á–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω –∫–∞–∫ **{report_type}**.")
        
        with st.spinner("–®–∞–≥ 2/2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ —à–∞–±–ª–æ–Ω—É (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç)..."):
            structured_data = extract_data_with_template(llm, all_text, report_type)
        
        if structured_data is None:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –æ—à–∏–±–æ–∫ –≤—ã—à–µ.")
        else:
            st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω—ã!")
            st.session_state.processed_data = structured_data

    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    if st.session_state.get("processed_data"):
        final_data = enrich_data_with_russian_names(st.session_state.processed_data, report_type)
        df = pd.DataFrame([item for item in final_data if item.get('value') is not None])
        
        st.header("–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        if not df.empty:
            df = df[["–°—Ç–∞—Ç—å—è (RU)", "Line Item (EN)", "value", "year", "unit"]]
            st.dataframe(df, use_container_width=True)
            
            excel_bytes = to_excel_bytes(df)
            st.download_button(
                label="üì• –°–∫–∞—á–∞—Ç—å –æ—Ç—á–µ—Ç –≤ Excel",
                data=excel_bytes,
                file_name=f"standard_report_{report_type.replace(' ', '_')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        else:
            st.warning("–í —Ç–µ–∫—Å—Ç–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π —Å—Ç–∞—Ç—å–∏ –∏–∑ —à–∞–±–ª–æ–Ω–∞ —Å —á–∏—Å–ª–æ–≤—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º.")
        
        with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω—ã–π JSON –æ—Ç LLM (–¥–æ –æ–±–æ–≥–∞—â–µ–Ω–∏—è)"):
            st.json(st.session_state.processed_data)
        with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å –≤–µ—Å—å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç"):
            st.text_area("–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç", all_text, height=400)

else:
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑.")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –≤ session_state
st.session_state['extract_text_from_file_func'] = extract_text_from_file
st.session_state['classify_report_func'] = classify_report
st.session_state['extract_data_with_template_func'] = extract_data_with_template
